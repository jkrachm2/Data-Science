{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcaffo/ds4bme_intro/blob/master/notebooks/notebook6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QliNPatWGeQF",
        "colab_type": "text"
      },
      "source": [
        "This example from the pytorch documentation [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) displays generating random y ad x dat and fitting a multi-layer neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gmWH2_GILQ",
        "colab_type": "code",
        "outputId": "460f97b3-7974-484e-9ad5-428fb776b4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 1.9933761358261108\n",
            "199 0.020633060485124588\n",
            "299 0.00045402691466733813\n",
            "399 1.4306728189694695e-05\n",
            "499 5.802120313092018e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWcVUq9RGxTB",
        "colab_type": "text"
      },
      "source": [
        "Let's update that example for our setting using the voxel level data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62iyChkPGwZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.linear_model as lm\n",
        "## this sets some style parameters\n",
        "sns.set()\n",
        "\n",
        "## Download in the data if it's not already there\n",
        "! if [ ! -e oasis.csv ]; \\\n",
        "  then wget https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv; \\\n",
        "fi;\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"oasis.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIwiOlRTIor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFraction = .75\n",
        "\n",
        "sample = np.random.uniform(size = 100) < trainFraction\n",
        "trainingDat = dat[sample]\n",
        "testingDat = dat[~sample]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tVT-AsOTPgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1f938b04-48b9-4fa2-8b94-160c233b8a7e"
      },
      "source": [
        "x = torch.from_numpy(dat[['PD','T1', 'T2', 'FLAIR_10', 'T1_10', 'T2_10', 'FLAIR_20']].values)\n",
        "y = torch.from_numpy(dat[['FLAIR']].values)\n",
        "\n",
        "##pytorch wants type as float\n",
        "x = x.float()\n",
        "y = y.float()\n",
        "\n",
        "xtraining = x[sample]\n",
        "xtesting = x[~sample]\n",
        "ytraining = y[sample]\n",
        "ytesting = y[~sample]\n",
        "\n",
        "[\n",
        " xtraining.size(),\n",
        " ytraining.size(),\n",
        " xtesting.size(),\n",
        " ytesting.size(),\n",
        "]\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([75, 7]),\n",
              " torch.Size([75, 1]),\n",
              " torch.Size([25, 7]),\n",
              " torch.Size([25, 1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UxGTdkaBdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the model\n",
        "## Dimension of the hidden layer\n",
        "H = 10\n",
        "\n",
        "## Number of predictors\n",
        "D_in = xtraining.size()[1]\n",
        "D_out = 1\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnoPaqh7Rm2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "9067a2a4-7d16-4efa-8ee0-8ef8d44db9d2"
      },
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    y_pred = model(xtraining)\n",
        "    loss = loss_fn(y_pred, ytraining)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 31.615375518798828\n",
            "199 28.612531661987305\n",
            "299 27.466083526611328\n",
            "399 26.587757110595703\n",
            "499 25.88320541381836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZswhY21bcwK",
        "colab_type": "code",
        "outputId": "bbefd7ef-cf11-4bd1-9ffc-7e99344e2755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "## try prediction\n",
        "ytesting_pred = model(xtesting)\n",
        "a = ytesting_pred.detach().numpy()\n",
        "\n",
        "plt.scatter(a[:,0], ytesting[:,0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff1e9f789b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEBCAYAAAB/rs7oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQ8AhiH4AcAwBD8AGOb/AXNAnA0INDjQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}