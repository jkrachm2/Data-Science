{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of notebook5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcaffo/ds4bme_intro/blob/master/notebooks/notebook5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIzXXVGuR9YM",
        "colab_type": "text"
      },
      "source": [
        "# Linear separable models\n",
        "\n",
        "We've now covered two ways to do prediction with a single variable, classification using logistic regression and prediction using a line and least squares. What if we have several predictiors? \n",
        "\n",
        "In both the logistic and linear regression models, we had a linear predictor, specifically, \n",
        "$$\n",
        "\\eta_i = \\beta_0 + \\beta_1 x_i.\n",
        "$$\n",
        "In the continuous case, we were modeling the expected value of the outcomes as linear. In the binary case, we were assuming that the naturual logarithm of the odds of a 1 outcome was linear. \n",
        "\n",
        "To estimate the unknown parameters, $\\beta_0$ and $\\beta_1$ we minimized\n",
        "$$\n",
        "\\sum_{i=1}^n || y_i - \\eta_i||^2 \n",
        "$$\n",
        "in the linear case and \n",
        "$$\n",
        "-\\sum_{i=1}^n \\left[\n",
        "  Y_i \\eta_i + \\log\\left\\{\\frac{1}{1 + e^{\\eta_i}} \\right\\} \\right].\n",
        "$$\n",
        "in the binary outcome case (where, recall, $\\eta_i$ depends on the parameters). \n",
        "\n",
        "We can easily extend these models to multiple predictors by assuming that the impact of the multiple predictors is linear and separable. That is,\n",
        "\n",
        "$$\n",
        "\\eta_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots \\beta_{p-1} x_{p-1,i}\n",
        "$$\n",
        "\n",
        "If we think about this as vectors and matrices, we obtain\n",
        "\n",
        "$$\n",
        "\\eta = X \\beta\n",
        "$$\n",
        "where $\\eta$ is an $n \\times 1$ vector, $X$ is an $n \\times p$ matrix with $i,j$ entry $x_{ij}$ and $\\beta$ is a $p\\times 1$ vector with entries $\\beta_j$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSoCaMXb4x-",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the voxel-level data that we've been working with. First let's load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eIqNlyifK-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMMLqAkYRxb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.linear_model as lm\n",
        "import sklearn as skl\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels as sm\n",
        "\n",
        "## this sets some style parameters\n",
        "sns.set()\n",
        "\n",
        "## Download in the data if it's not already there\n",
        "! if [ ! -e oasis.csv ]; \\\n",
        "then wget https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv; \\\n",
        "fi;\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"oasis.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUih09BMdi9_",
        "colab_type": "text"
      },
      "source": [
        "Let's first try to fit the proton density data from the other imaging data. I'm going to use the `statsmodels` version of linear models since it has a nice format for dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onw6CyaCdrtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFraction = .75\n",
        "\n",
        "sample = np.random.uniform(size = 100) < trainFraction\n",
        "trainingDat = dat[sample]\n",
        "testingDat = dat[~sample]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDJOnSsxe2N5",
        "colab_type": "code",
        "outputId": "140b3f55-7e65-4bcf-91c3-417127a8769d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "results = smf.ols('PD ~ FLAIR + T1 + T2  + FLAIR_10 + T1_10 + T2_10 + FLAIR_20', data = trainingDat).fit()\n",
        "print(results.summary2())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Results: Ordinary least squares\n",
            "=================================================================\n",
            "Model:              OLS              Adj. R-squared:     0.773   \n",
            "Dependent Variable: PD               AIC:                72.6331 \n",
            "Date:               2019-09-23 19:22 BIC:                91.2790 \n",
            "No. Observations:   76               Log-Likelihood:     -28.317 \n",
            "Df Model:           7                F-statistic:        37.44   \n",
            "Df Residuals:       68               Prob (F-statistic): 6.19e-21\n",
            "R-squared:          0.794            Scale:              0.13787 \n",
            "------------------------------------------------------------------\n",
            "               Coef.   Std.Err.     t     P>|t|    [0.025   0.975]\n",
            "------------------------------------------------------------------\n",
            "Intercept      0.1781    0.1441   1.2366  0.2205  -0.1093   0.4656\n",
            "FLAIR         -0.0103    0.0909  -0.1131  0.9103  -0.1917   0.1711\n",
            "T1            -0.2067    0.0873  -2.3664  0.0208  -0.3810  -0.0324\n",
            "T2             0.6145    0.0825   7.4528  0.0000   0.4500   0.7790\n",
            "FLAIR_10      -0.2880    0.3412  -0.8442  0.4015  -0.9688   0.3928\n",
            "T1_10          0.2394    0.1694   1.4131  0.1622  -0.0987   0.5775\n",
            "T2_10          0.0887    0.3102   0.2861  0.7757  -0.5302   0.7076\n",
            "FLAIR_20       2.0992    0.7424   2.8278  0.0062   0.6179   3.5806\n",
            "-----------------------------------------------------------------\n",
            "Omnibus:               4.022        Durbin-Watson:          2.111\n",
            "Prob(Omnibus):         0.134        Jarque-Bera (JB):       3.904\n",
            "Skew:                  -0.238       Prob(JB):               0.142\n",
            "Kurtosis:              4.003        Condition No.:          41   \n",
            "=================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UrWqsZAfF1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "fce680da-2fbb-476f-a5b9-b013192885b8"
      },
      "source": [
        "x = dat[['FLAIR','T1', 'T2', 'FLAIR_10', 'T1_10', 'T2_10', 'FLAIR_20']]\n",
        "y = dat[['GOLD_Lesions']]\n",
        "## Add the intercept column\n",
        "x = sm.tools.add_constant(x)\n",
        "\n",
        "xtraining = x[sample]\n",
        "xtesting = x[~sample]\n",
        "ytraining = y[sample]\n",
        "ytesting = y[~sample]\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaU1zUQluyFb",
        "colab_type": "code",
        "outputId": "0bf756bd-d907-413a-a31e-4c92159e4d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "fit = sm.discrete.discrete_model.Logit(ytraining, xtraining).fit()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.253784\n",
            "         Iterations 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clrxtIgQvDhJ",
        "colab_type": "code",
        "outputId": "2fc144fe-1bd0-450b-e180-5788b1ca6769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "fit.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>     <td>GOLD_Lesions</td>   <th>  No. Observations:  </th>  <td>    71</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    63</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Mon, 23 Sep 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.6515</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>18:22:05</td>     <th>  Log-Likelihood:    </th> <td> -17.150</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -49.206</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.266e-11</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>    <td>   -4.7783</td> <td>    1.985</td> <td>   -2.407</td> <td> 0.016</td> <td>   -8.668</td> <td>   -0.888</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR</th>    <td>    2.6983</td> <td>    1.353</td> <td>    1.994</td> <td> 0.046</td> <td>    0.046</td> <td>    5.351</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T1</th>       <td>    3.0484</td> <td>    1.306</td> <td>    2.334</td> <td> 0.020</td> <td>    0.489</td> <td>    5.608</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T2</th>       <td>    2.1443</td> <td>    1.196</td> <td>    1.793</td> <td> 0.073</td> <td>   -0.199</td> <td>    4.488</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR_10</th> <td>    4.9421</td> <td>    4.256</td> <td>    1.161</td> <td> 0.246</td> <td>   -3.400</td> <td>   13.284</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T1_10</th>    <td>   -0.3192</td> <td>    2.331</td> <td>   -0.137</td> <td> 0.891</td> <td>   -4.888</td> <td>    4.250</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T2_10</th>    <td>   -4.9192</td> <td>    4.014</td> <td>   -1.226</td> <td> 0.220</td> <td>  -12.786</td> <td>    2.947</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR_20</th> <td>  -16.6939</td> <td>    9.496</td> <td>   -1.758</td> <td> 0.079</td> <td>  -35.306</td> <td>    1.918</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:           GOLD_Lesions   No. Observations:                   71\n",
              "Model:                          Logit   Df Residuals:                       63\n",
              "Method:                           MLE   Df Model:                            7\n",
              "Date:                Mon, 23 Sep 2019   Pseudo R-squ.:                  0.6515\n",
              "Time:                        18:22:05   Log-Likelihood:                -17.150\n",
              "converged:                       True   LL-Null:                       -49.206\n",
              "Covariance Type:            nonrobust   LLR p-value:                 2.266e-11\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const         -4.7783      1.985     -2.407      0.016      -8.668      -0.888\n",
              "FLAIR          2.6983      1.353      1.994      0.046       0.046       5.351\n",
              "T1             3.0484      1.306      2.334      0.020       0.489       5.608\n",
              "T2             2.1443      1.196      1.793      0.073      -0.199       4.488\n",
              "FLAIR_10       4.9421      4.256      1.161      0.246      -3.400      13.284\n",
              "T1_10         -0.3192      2.331     -0.137      0.891      -4.888       4.250\n",
              "T2_10         -4.9192      4.014     -1.226      0.220     -12.786       2.947\n",
              "FLAIR_20     -16.6939      9.496     -1.758      0.079     -35.306       1.918\n",
              "==============================================================================\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkCEdWt0xGzn",
        "colab_type": "text"
      },
      "source": [
        "Now let's evaluate our prediction. Here, we're not going to classify as 0 or 1, but rather estimate the prediction. Note, we then would need to pick a threshold to have a classifier. We could use .5 as our threshold. However, it's often the case that we don't necessarily want to threshold at specifically that level. A solution for evalution is to plot how the sensitivity and specificity change by the threshold. \n",
        "\n",
        "In other words, consider the triplets\n",
        "$$\n",
        "(t, sens(t), spec(t))\n",
        "$$\n",
        "where $t$ is the threshold, `sens(t)` is the sensitivity at threshold $t$, `spec(t)` is the specificity at threshold `t`. \n",
        "\n",
        "Necessarily, the sensitivity and specificity \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxlcuTECxCyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "94d8070e-71a3-42f1-a4f4-2a5354602f82"
      },
      "source": [
        "phatTesting = fit.predict(xtesting)\n",
        "\n",
        "## See here for plotting\n",
        "## https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
        "fpr, tpr, threshold = skl.metrics.roc_curve(ytesting, phatTesting)\n",
        "roc_auc = skl.metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEcCAYAAAAGD4lRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaXw2nFg6UoO",
        "colab_type": "text"
      },
      "source": [
        "## Aside different python packages\n",
        "\n",
        "So far we've explored several plotting libraries including: default pandas methods, matplotlib, seaborn and plotly. We've also looked at several fitting libraries including to some extent numpy, but especially scikitlearn and statsmodels. What's the difference? Well, these packages are all mantained by different people and have different features and goals. For example, scikitlearn is more expansive than statsmodels, but statsmodels functions more like one is used to with statistical output. Matplotlib is very expansive, but seaborn has nicer default options and is a little easier. So, when doing data science with python, one has to get used to trying out a few packages, weighing the cost and benefits of each, and picking one. \n",
        "\n",
        "'statsmodels', what we're using above, has multiple methods for fitting binary models including: `sm.Logit`, `smf.logit`, `BinaryModel` and `glm`. Here I'm just going to use `Logit` which does not use the formula syntax of `logit`. Note, by default, this does not add an intercept this way. So, I'm adding a column of ones, which adds an intercept.\n",
        "\n",
        "Consider the following which uses the formula API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj_2oMxvWC4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "22d63911-ebca-429a-b14b-af07c39a59bb"
      },
      "source": [
        "results = smf.logit(formula = 'GOLD_Lesions ~ FLAIR + T1 + T2 + FLAIR_10 + T1_10 + T2_10 + FLAIR_20', data = trainingDat).fit()\n",
        "results.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.241546\n",
            "         Iterations 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>     <td>GOLD_Lesions</td>   <th>  No. Observations:  </th>  <td>    71</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    63</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Mon, 23 Sep 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.6515</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>18:23:47</td>     <th>  Log-Likelihood:    </th> <td> -17.150</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -49.206</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.266e-11</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -4.7783</td> <td>    1.985</td> <td>   -2.407</td> <td> 0.016</td> <td>   -8.668</td> <td>   -0.888</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR</th>     <td>    2.6983</td> <td>    1.353</td> <td>    1.994</td> <td> 0.046</td> <td>    0.046</td> <td>    5.351</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T1</th>        <td>    3.0484</td> <td>    1.306</td> <td>    2.334</td> <td> 0.020</td> <td>    0.489</td> <td>    5.608</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T2</th>        <td>    2.1443</td> <td>    1.196</td> <td>    1.793</td> <td> 0.073</td> <td>   -0.199</td> <td>    4.488</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR_10</th>  <td>    4.9421</td> <td>    4.256</td> <td>    1.161</td> <td> 0.246</td> <td>   -3.400</td> <td>   13.284</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T1_10</th>     <td>   -0.3192</td> <td>    2.331</td> <td>   -0.137</td> <td> 0.891</td> <td>   -4.888</td> <td>    4.250</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>T2_10</th>     <td>   -4.9192</td> <td>    4.014</td> <td>   -1.226</td> <td> 0.220</td> <td>  -12.786</td> <td>    2.947</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>FLAIR_20</th>  <td>  -16.6939</td> <td>    9.496</td> <td>   -1.758</td> <td> 0.079</td> <td>  -35.306</td> <td>    1.918</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:           GOLD_Lesions   No. Observations:                   71\n",
              "Model:                          Logit   Df Residuals:                       63\n",
              "Method:                           MLE   Df Model:                            7\n",
              "Date:                Mon, 23 Sep 2019   Pseudo R-squ.:                  0.6515\n",
              "Time:                        18:23:47   Log-Likelihood:                -17.150\n",
              "converged:                       True   LL-Null:                       -49.206\n",
              "Covariance Type:            nonrobust   LLR p-value:                 2.266e-11\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -4.7783      1.985     -2.407      0.016      -8.668      -0.888\n",
              "FLAIR          2.6983      1.353      1.994      0.046       0.046       5.351\n",
              "T1             3.0484      1.306      2.334      0.020       0.489       5.608\n",
              "T2             2.1443      1.196      1.793      0.073      -0.199       4.488\n",
              "FLAIR_10       4.9421      4.256      1.161      0.246      -3.400      13.284\n",
              "T1_10         -0.3192      2.331     -0.137      0.891      -4.888       4.250\n",
              "T2_10         -4.9192      4.014     -1.226      0.220     -12.786       2.947\n",
              "FLAIR_20     -16.6939      9.496     -1.758      0.079     -35.306       1.918\n",
              "==============================================================================\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}