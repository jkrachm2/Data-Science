{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QliNPatWGeQF",
        "colab_type": "text"
      },
      "source": [
        "This example from the pytorch documentation [here](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) displays generating random y ad x dat and fitting a multi-layer neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gmWH2_GILQ",
        "colab_type": "code",
        "outputId": "f535175f-e02b-4e56-eba0-149f0a7e3206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.1936633586883545\n",
            "199 0.030526122078299522\n",
            "299 0.0010051147546619177\n",
            "399 5.2805262384936213e-05\n",
            "499 3.4086278901668265e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWcVUq9RGxTB",
        "colab_type": "text"
      },
      "source": [
        "Let's update that example for our setting using the voxel level data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62iyChkPGwZD",
        "colab_type": "code",
        "outputId": "93c30b84-893e-484c-eda2-cd7865196eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.linear_model as lm\n",
        "## this sets some style parameters\n",
        "sns.set()\n",
        "\n",
        "## Download in the data if it's not already there\n",
        "! if [ ! -e oasis.csv ]; \\\n",
        "  then wget https://raw.githubusercontent.com/jkrachm2/Data-Science/master/Master%20Repo/ds4bme_intro-master/data/oasis.csv; \\\n",
        "fi;\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"oasis.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-23 22:32:33--  https://raw.githubusercontent.com/jkrachm2/Data-Science/master/Master%20Repo/ds4bme_intro-master/data/oasis.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22274 (22K) [text/plain]\n",
            "Saving to: ‘oasis.csv’\n",
            "\n",
            "\roasis.csv             0%[                    ]       0  --.-KB/s               \roasis.csv           100%[===================>]  21.75K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-03-23 22:32:33 (1.52 MB/s) - ‘oasis.csv’ saved [22274/22274]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIwiOlRTIor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainFraction = .75\n",
        "\n",
        "sample = np.random.uniform(size = 100) < trainFraction\n",
        "trainingDat = dat[sample]\n",
        "testingDat = dat[~sample]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tVT-AsOTPgN",
        "colab_type": "code",
        "outputId": "e0c69d5d-f46f-4338-97cd-6582215bd272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "x = torch.from_numpy(dat[['PD','T1', 'T2', 'FLAIR_10', 'T1_10', 'T2_10', 'FLAIR_20']].values)\n",
        "y = torch.from_numpy(dat[['FLAIR']].values)\n",
        "\n",
        "##pytorch wants type as float\n",
        "x = x.float()\n",
        "y = y.float()\n",
        "\n",
        "xtraining = x[sample]\n",
        "xtesting = x[~sample]\n",
        "ytraining = y[sample]\n",
        "ytesting = y[~sample]\n",
        "\n",
        "[\n",
        " xtraining.size(),\n",
        " ytraining.size(),\n",
        " xtesting.size(),\n",
        " ytesting.size(),\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([78, 7]),\n",
              " torch.Size([78, 1]),\n",
              " torch.Size([22, 7]),\n",
              " torch.Size([22, 1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UxGTdkaBdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the model\n",
        "## Dimension of the hidden layer\n",
        "H = 10\n",
        "\n",
        "## Number of predictors\n",
        "D_in = xtraining.size()[1]\n",
        "D_out = 1\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnoPaqh7Rm2M",
        "colab_type": "code",
        "outputId": "b0b9f79c-e922-44e0-c47b-d9a68649be21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    y_pred = model(xtraining)\n",
        "    loss = loss_fn(y_pred, ytraining)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 29.2286319732666\n",
            "199 25.58927345275879\n",
            "299 24.688426971435547\n",
            "399 24.08563232421875\n",
            "499 23.58952522277832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZswhY21bcwK",
        "colab_type": "code",
        "outputId": "3a2dd4f4-3757-4036-f343-8614e17d93f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "## try prediction\n",
        "ytesting_pred = model(xtesting)\n",
        "a = ytesting_pred.detach().numpy()\n",
        "\n",
        "plt.scatter(a[:,0], ytesting[:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f020ec6cc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}