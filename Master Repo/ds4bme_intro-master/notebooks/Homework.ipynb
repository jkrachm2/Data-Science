{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcaffo/ds4bme_intro/blob/master/notebooks/Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Ez59sDpvap",
        "colab_type": "text"
      },
      "source": [
        "Here's some homework to get you ready for the next class. Try to do the homework right after or before each class.\n",
        "\n",
        "# Lecture 0\n",
        "\n",
        "1. Get a colab account; create an empty notebook and play around with python in colab\n",
        "2. Duplicate the first colab notebook from class.\n",
        "3. Create a github account; create a repository; we'll email you a github classroom id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu8yVx9ep4HX",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 1\n",
        "\n",
        "1. Fit a model to the kirby 21 dataset into colab. Do a scatterplot of the left telencephalon **(type 1 level 1) volume** by the right.\n",
        "2. Create a vector of the left telencelphalon **(type 1 level 1) volume** values and the right. Demean each. Fit a regression through the origin model with the left telecephalon as the outcome and the right as the predictor. Also do the same with the left as the predictor and the right as the outcome. Plot the fitted lines on your scatterplot. To obtain the regression slope, both code it yourself and use a regression function in python.\n",
        "3. Consider a regression through the origin model $Y=BX$. What would be the impact on the estimate of $B$ if we replaced $X$ by $cX$ where $c$ is a positive constant?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wjsCSDNp6EM",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 2\n",
        "\n",
        "1. Let $X_i$ be a group indicator so that \n",
        "$$\n",
        "x_i = I(i \\in G_1)\n",
        "$$\n",
        "I.e. takes the value $1$ when $i$ is in group 1 and 0 if $i$ is in group 0. Consider optimizing \n",
        "$$\n",
        "\\sum_{i=1}^n (Y_i - \\beta_0 - \\beta_1 X_i)^2.\n",
        "$$\n",
        "If $\\hat Y = \\hat \\beta_0 + \\hat \\beta_1 X$ argue that $\\hat Y$ is the group mean for group 1 if $X=1$ and the group mean for group 0 if $X=0$. \n",
        "2. Write a python function that takes an X and Y vector and returns an estimated $\\beta_0$ and $\\beta_1$ from linear regression. Check your function versus one of the prewritten ones.\n",
        "3. Consider the Kirby 21 data. Plot a scatter plot of the left diencephalon (type 1 level 1) and the right. Find the best line fit for predicting the right using the left. Plot the line on the scatterplot. Find the best fit line for predicting the left using the right as a predictor. Plot this on the same plot.\n",
        "4. Argue that if you take the vectors $Y$ and $X$ and divide them by their standard deviations (respectively), the slope for either regressing $Y$ on $X$ or $X$ on $Y$ is simply the correlation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vugy7xdpkdE9",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 3\n",
        "\n",
        "1. Consider the logistic curve \n",
        "$$\n",
        "f(x) = \\frac{e^{\\beta_0 + \\beta_1x}}{1 + e^{\\beta_0 + \\beta_1 x}}.\n",
        "$$\n",
        "Plot the curve for various values of $\\beta_0$ and $\\beta_1$.\n",
        "2. Show that if \n",
        "$$\n",
        "P(Y=1~|~X =x) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}}\n",
        "$$\n",
        "then $\\beta_0 + \\beta_1 x$ is the logarithm of the odds \n",
        "$$\n",
        "\\log\\left\\{ \\frac{P(Y = 1 ~|~ X =x)}{1 - P(Y = 1 ~|~ X =x)}\\right\\}.\n",
        "$$\n",
        "3. Argue that the logistic curve from Question 1. $f(x)$ is between $0$ and $1$ for any $X$ (so is a good model for a probability). Also argue that $f(X)$ it is either increasing or decreasing in $X$.\n",
        "4. Describe what changing $\\beta_0$ and $\\beta_1$ does to $f(x)$. \n",
        "5. Let \n",
        "$$\n",
        "O(Y = 1 ~| X = x) = \\frac{P(Y = 1 ~|~ X =x)}{1 - P(Y = 1 ~|~ X=x)}\n",
        "$$\n",
        "be the odds associated with $P(Y = 1 ~|~ X=x)$. Show that if the model from question 2. holds, then \n",
        "$$\n",
        "e^{\\beta_1} = \\frac{O(Y = 1 ~| X = x + 1)}{O(Y = 1 ~| X = x)}\n",
        "$$\n",
        "In other words, $e^{\\beta_1}$ is the odds ratio for a one unit change in $X$ and $\\beta_1$ is the log of the odds ratio for a one unit change in $X$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYwxhKedcpHg",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 4\n",
        "\n",
        "In this lecture, we discussed fitting logistic regression models.\n",
        "\n",
        "1. Consider the model $P(Y_i = 1) = \\frac{e^{\\beta_0 }}{1 + e^{\\beta_0 }}$ and then the likelihood\n",
        "$$\n",
        "\\prod_{i=1}^n\n",
        "\\left\\{ \\frac{e^{\\beta_0 }}{1 + e^{\\beta_0 }} \\right\\}^{y_i}\n",
        "\\left\\{ \\frac{1}{1 + e^{\\beta_0 }} \\right\\}^{1 - y_i}.\n",
        "$$\n",
        "Maximize the natural logarithm of the likelihood to obtain the estimate for $\\beta_0$. Show that it's equal to\n",
        "$$\n",
        "\\hat \\beta = \\log\\left( \\frac{\\bar Y}{1 - \\bar Y}  \\right).\n",
        "$$\n",
        "where here we're assuming that $0 < \\bar Y < 1$.\n",
        "2. Consider the voxel level lesion data discussed in class. Fit a logistic regression model where lesion status at a voxel is the outcome and PD is the predictor. Plot your estimated sigmoid curve on a scatterplot of PD versus lesion score. Split your data into a test and training set and check the sensitivity, specificity and accuracy of your predictions. Here predict that a voxel is a lesion if the predicted probability is greater than 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11Q3FBpWC1G",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 5\n",
        "\n",
        "1. For the voxel level imaging data, use least squares to predict FLAIR using the other imaging modalities. Split your data into a test and training set. Evalute your model using the testing data.\n",
        "2. For the voxel level imaging data, use logistic regression to predict Lesions using PD, FLAIR, T1 and T2. Split your data into training and testing sets. Then add the the 10 smoothed data and compare prediction accuracy, sensitivity and specificty between the two approaches. Finally, add the 20 smoothed data and repeat. Does it appear that adding the smoothed image data improves prediction enough?\n",
        "3. For your model in 1. and your first model in 2, interpret your coefficients."
      ]
    }
  ]
}